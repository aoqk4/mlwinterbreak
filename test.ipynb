{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PyTorch Operation\n",
    "## numpy + AutoGrad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy ndarray와 비슷하다\n",
    "\n",
    "Torch는 numpy가 GPU를 쓸수 있는 데이터 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3 4]\n",
      " [5 6 7 8 9]]\n",
      "ndim : 2 shape :  (2, 5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_array = np.arange(10).reshape(2, 5)\n",
    "print(n_array)\n",
    "print(\"ndim :\", n_array.ndim, \"shape : \", n_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8., 9.]])\n",
      "ndim : 2 shape :  torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t_array = torch.FloatTensor(n_array)\n",
    "print(t_array)\n",
    "print(\"ndim :\", t_array.ndim, \"shape : \", t_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  5],\n",
       "        [10,  5]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[3, 5], [10, 5]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    x_data_cuda = x_data.to(\"cuda\")\n",
    "\n",
    "x_data_cuda.device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reshape (Copy) --> view (Reference)\n",
    "\n",
    "1차원 삭제(압축) --> squeeze\n",
    "\n",
    "1차원 추가 --> unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8736, 0.0661],\n",
       "         [0.8215, 0.5333],\n",
       "         [0.9676, 0.5091]],\n",
       "\n",
       "        [[0.3925, 0.4416],\n",
       "         [0.6288, 0.6051],\n",
       "         [0.0751, 0.9612]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_ex = torch.rand(size=(2,3,2))\n",
    "tensor_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8736, 0.0661, 0.8215, 0.5333, 0.9676, 0.5091],\n",
       "        [0.3925, 0.4416, 0.6288, 0.6051, 0.0751, 0.9612]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_ex.view([-1, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8736, 0.0661, 0.8215, 0.5333, 0.9676, 0.5091],\n",
       "        [0.3925, 0.4416, 0.6288, 0.6051, 0.0751, 0.9612]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_ex.reshape([-1, 6])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적인 행렬, 스칼라 덧셈은 같다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dot (벡터간에는) --> mm (행렬 간에는)\n",
    "\n",
    "mm vs matmul \n",
    "matmul은 알아서 차원은 맞추어 준다 (broadcasting)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.functional mod를 통해 다양한 수식 변환을 지원한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3458, 0.4224, 0.2318])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "tensor = torch.FloatTensor([0.5, 0.7, 0.1])\n",
    "\n",
    "h_tensor = F.softmax(tensor, dim=0)\n",
    "h_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 4, 4, 4, 2, 1, 4, 1, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randint(5,(10,5))\n",
    "\n",
    "y_label = y.argmax(dim=1)\n",
    "\n",
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.one_hot(y_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyTorch의 핵심은 자동미분 --> backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(40.)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "y = w ** 2\n",
    "\n",
    "z = 10 * y + 2\n",
    "\n",
    "z.backward()\n",
    "w.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "febstudy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c6d7e1523ba522d0c53f6044fccb8eafec3763db67a71776f2b57cacf672f80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
